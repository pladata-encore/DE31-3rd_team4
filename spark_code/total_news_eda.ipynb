{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bca25222-c966-44bf-a896-d7430568aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess, json\n",
    "from datetime import datetime, timedelta\n",
    "from pyarrow import fs\n",
    "import pyarrow as pa\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fee0d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_hdfs(hdfs_info):\n",
    "    user = hdfs_info[\"user\"]\n",
    "    host = hdfs_info[\"host\"]\n",
    "    port = hdfs_info[\"port\"]\n",
    "    \n",
    "    try:\n",
    "        classpath = subprocess.Popen([hdfs_info[\"hdfs_path\"], \"classpath\", \"--glob\"], stdout=subprocess.PIPE).communicate()[0]\n",
    "        os.environ[\"CLASSPATH\"] = classpath.decode(\"utf-8\")\n",
    "        hdfs = fs.HadoopFileSystem(host=hdfs_info[\"host\"], port=hdfs_info[\"port\"], user=hdfs_info[\"user\"])\n",
    "        \n",
    "        return hdfs\n",
    "    except Exception as e:\n",
    "        #print(f\"Failed to connect hdfs {user}@{host}:{port}\")\n",
    "        #log(f\"Failed to connect hdfs {user}@{host}:{port}\", 1)\n",
    "        return None\n",
    "\n",
    "\n",
    "def compare_file_date(filename, target_date):\n",
    "    # 파일명에서 날짜 추출 (예: kbs_2024-07-04_0012.csv)\n",
    "    try:\n",
    "        file_date_str = filename.split('_')[1]  # \"2024-07-04\"\n",
    "        file_date = datetime.strptime(file_date_str, \"%Y-%m-%d\").date()  # datetime.date(2024, 7, 4)\n",
    "        \n",
    "        # 현재 날짜 가져오기\n",
    "        current_date = target_date.date()  # 현재 날짜 (예: datetime.date(2024, 7, 4))\n",
    "        \n",
    "        # 날짜 비교\n",
    "        if file_date == current_date:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_file_list_from_hdfs(hdfs, hdfs_path):\n",
    "    # HDFS 경로에서 파일 목록 가져오기\n",
    "    try:\n",
    "        file_infos = hdfs.get_file_info(pa.fs.FileSelector(hdfs_path, recursive=False))\n",
    "        # if not file_info_list.is_directory:\n",
    "        #     raise Exception(f\"{hdfs_path} is not a directory\")\n",
    "        \n",
    "        file_list = [file_info.path for file_info in file_infos]\n",
    "        \n",
    "        return file_list\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting file list from HDFS: {e}\")\n",
    "    \n",
    "def filter_files_by_date(file_list, target_date):\n",
    "    filtered_files = [file for file in file_list if compare_file_date(file, target_date)]\n",
    "    return filtered_files\n",
    "\n",
    "def str_preprocess(_str):\n",
    "    return ' '.join(_str.replace(\"\\n\", \" \").replace(\"\\t\", \" \").replace(\"/\", \"\").split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5feb06e5-767c-481e-abc1-2748966f86c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/05 09:08:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2024-07-05 09:08:46,191 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "hdfs_info_path = \"./API_KEYS/HDFS_INFO.json\"\n",
    "target_hdfs_dir_path = '/P3T5'\n",
    "with open(hdfs_info_path, 'r') as header_f:\n",
    "    hdfs_info = json.load(header_f)\n",
    "\n",
    "conf = pyspark.SparkConf() \\\n",
    "            .setAppName(\"hdfs2db\") \\\n",
    "            .setMaster(\"spark://master:7077\") \\\n",
    "            .set(\"spark.blockManager.port\", \"10025\") \\\n",
    "            .set(\"spark.driver.blockManager.port\", \"10026\") \\\n",
    "            .set(\"spark.driver.port\", \"10027\") \\\n",
    "            .set(\"spark.cores.max\", \"2\") \\\n",
    "            .set(\"spark.jars\", \"/opt/spark/jars\")\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "hdfs_connection = connect_hdfs(hdfs_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "743d3f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://master:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>hdfs2db</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7d0710031f00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2d61677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7962801",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date = datetime.now() - timedelta(1)\n",
    "total_file_list = get_file_list_from_hdfs(hdfs_connection, target_hdfs_dir_path)\n",
    "target_file_list = filter_files_by_date(total_file_list, target_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fae138c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/P3T5/cnn_2024-07-04_1715.csv',\n",
       " '/P3T5/cnn_2024-07-04_1736.csv',\n",
       " '/P3T5/cnn_2024-07-04_1759.csv',\n",
       " '/P3T5/cnn_2024-07-04_2300.csv',\n",
       " '/P3T5/kbs_2024-07-04_1720.csv',\n",
       " '/P3T5/kbs_2024-07-04_1721.csv',\n",
       " '/P3T5/kbs_2024-07-04_1725.csv',\n",
       " '/P3T5/kbs_2024-07-04_1745.csv',\n",
       " '/P3T5/kbs_2024-07-04_1746.csv',\n",
       " '/P3T5/kbs_2024-07-04_2300.csv',\n",
       " '/P3T5/mbc_2024-07-04_1705.csv',\n",
       " '/P3T5/mbc_2024-07-04_1720.csv',\n",
       " '/P3T5/mbc_2024-07-04_1742.csv',\n",
       " '/P3T5/mbc_2024-07-04_1754.csv',\n",
       " '/P3T5/mbc_2024-07-04_1804.csv',\n",
       " '/P3T5/mbc_2024-07-04_2300.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c30335",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_file_list = [file for file in target_file_list if file.startwith(\"kbs\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8031172-da34-462f-8cc3-641f971ee605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------------------+-----------------------------------+--------+-------------------+--------------------+\n",
      "|institution|                     articleTitle|                    articleContents|category|            regDate|             getDate|\n",
      "+-----------+---------------------------------+-----------------------------------+--------+-------------------+--------------------+\n",
      "|        KBS|    \"(슈퍼5시)\"\"집값 추세 상승...|       \" [앵커]   정부가 올해 하...|    경제|2024-07-04 17:14:18|2024-07-04 17:20:...|\n",
      "|        KBS|   국토부, 65세이상 버스·택시 ...|     정부가 만 65세 이상 운수업 ...|    경제|2024-07-04 17:13:03|2024-07-04 17:20:...|\n",
      "|        KBS|  금감원 '뻥튀기 상장' 파두 관...|\"금융감독원 자본시장특별사법경찰...|    경제|2024-07-04 17:13:02|2024-07-04 17:20:...|\n",
      "|        KBS|    코스피 연고점 경신 2,820대...|  간밤 미국의 기술주 강세와 국채...|    경제|2024-07-04 17:08:44|2024-07-04 17:20:...|\n",
      "|        KBS|    \"금감원, \"\"직원 사칭 '가상...|  \"금융감독원 직원을 사칭해 가상...|    경제|2024-07-04 16:42:26|2024-07-04 17:20:...|\n",
      "|        KBS|   \"'화성 아리셀 화재' 피의자 ...|     \"31명의 사상자를 낸 아리셀 ...|    경제|2024-07-04 16:35:51|2024-07-04 17:20:...|\n",
      "|        KBS|     \"벤처업계 \"\"3분기 경기, 2...|   벤처기업들이 3분기 경기가 2분...|    경제|2024-07-04 15:53:52|2024-07-04 17:20:...|\n",
      "|        KBS|   부동산원, 7월 첫주 '서울 아...|  \"서울의 주간 아파트 매매가격이...|    경제|2024-07-04 15:33:36|2024-07-04 17:20:...|\n",
      "|        KBS|     \"삼성전자, 조직 개편 'HBM...|     \"삼성전자가 HBM(고대역폭 메...|    경제|2024-07-04 15:20:20|2024-07-04 17:20:...|\n",
      "|        KBS| 삼성전자 반도체, 성과급 '기본...| 삼성전자 반도체를 담당하는 디바...|    경제|2024-07-04 15:19:38|2024-07-04 17:20:...|\n",
      "|        KBS|   \"국토부 \"\"집값 추세적 상승 ...|   \"최근 서울을 중심으로 집값 상...|    경제|2024-07-04 15:07:20|2024-07-04 17:20:...|\n",
      "|        KBS|   \"\"\"주택화재보험 특약 가입 5...| 화재 위험을 기본적으로 보장하되...|    경제|2024-07-04 14:02:04|2024-07-04 17:20:...|\n",
      "|        KBS|   \"(슈퍼광장)\"\"한우 키워봐야 ...|       \" [앵커]   한우를 키우는 ...|    경제|2024-07-04 12:50:31|2024-07-04 17:20:...|\n",
      "|        KBS|\"인터넷용대체(슈퍼광장)줄줄이 ...|        \"   [앵커]   최근 재계에...|    경제|2024-07-04 12:45:21|2024-07-04 17:20:...|\n",
      "|        KBS|  \"대체(슈퍼광장)\"\"수수료 변경...|          \"   [앵커]   국내 1위 ...|    경제|2024-07-04 12:43:17|2024-07-04 17:20:...|\n",
      "|        KBS|    (12시)주택매매 축소 영향…1...|   \"아파트 분양 물량 축소 등으로...|    경제|2024-07-04 12:02:44|2024-07-04 17:20:...|\n",
      "|        KBS|     \"(12시)금융당국 \"\"특금법 ...|금융당국이 특정금융정보법상 신고...|    경제|2024-07-04 12:02:42|2024-07-04 17:20:...|\n",
      "|        KBS|  (12시)가상자산도 시세조종 등...| 주식시장과 같이 앞으로 가상자산...|    경제|2024-07-04 12:02:41|2024-07-04 17:20:...|\n",
      "|        KBS|      (12시)공정위, '3개월 내 ...|  \"공정거래위원회는 공기업 등 취...|    경제|2024-07-04 12:02:40|2024-07-04 17:20:...|\n",
      "|        KBS|       (1200) 이달 25일까지 부...|  부가가치세를 내야 하는 개인·법...|    경제|2024-07-04 12:02:39|2024-07-04 17:20:...|\n",
      "+-----------+---------------------------------+-----------------------------------+--------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_options = {\n",
    "            \"header\": True,\n",
    "            \"inferSchema\": True,\n",
    "            \"sep\": \"|\",\n",
    "            \"ignoreLeadingWhiteSpace\": True,\n",
    "            \"ignoreTrailingWhiteSpace\": True,\n",
    "            \"multiLine\": False,\n",
    "        }\n",
    "\n",
    "if target_file_list:\n",
    "    df_list = [spark.read.csv(f\"hdfs://{file}\", header=True, inferSchema=True, sep=\"|\", ignoreLeadingWhiteSpace=True, ignoreTrailingWhiteSpace=True, multiLine=True) for file in target_file_list]\n",
    "    combined_df = df_list[0]\n",
    "    for df in df_list[1:]:\n",
    "        combined_df = combined_df.union(df)\n",
    "    \n",
    "    # 결과 DataFrame 보여주기\n",
    "    combined_df.show()\n",
    "else:\n",
    "    print(\"No files found for the current date.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd5eb3c9-8de0-486a-9263-4c6178e0b4e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+-------------------+---------------------------+\n",
      "|institution|articleTitle                                                         |articleContents                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |category|regDate            |getDate                    |\n",
      "+-----------+---------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+-------------------+---------------------------+\n",
      "|KBS        |\"(슈퍼5시)\"\"집값 추세 상승 제한적…공공 공급 확대, 속도감 있게 추진\"\"\"|\" [앵커]   정부가 올해 하반기 2만 가구 규모의  신규 택지를 발표하는 등 공공 차원의 공급 확대를 속도감 있게 추진하겠다고 밝혔습니다.   최근 서울을 중심으로 일부 지역 부동산 시장이 상승세를 보이고 있지만 가계대출 관리 기조 등을 감안하면 상승 추세로 이어지긴 어렵다고 전망했습니다.   보도에 손서영 기자입니다.   [리포트]   정부가 올해 하반기 수도권을 중심으로 2만 호 이상의 신규 택지를 발굴해 공급하겠다고 밝혔습니다.   지자체 협의와   후보지 용역 절차에  2~3개월이 소요되지만 시장 상황에 따라 최대한 단축해 빠르게 발표한다는 계획입니다.   진현환국토교통부 1차관 [인터뷰] \"\"현재와 같이 민간 공급 여건이 위축되어 있는 상황에서는 공급 보완이 필요한 만큼 공공의 역할도 강화해 나갈 계획입니다.\"\"   올해와 내년 공급되는  3기 신도시 등  기존 정책도 속도감 있게 추진해 공급 부족 우려를  해소하기로 했습니다.   시세보다 저렴하게 전·월세로 거주할 수 있는  빌라와 다세대주택 등 공공 비아파트도  향후 2년간 12만 가구 공급합니다.   최근 서울과  수도권을 중심으로 부동산 가격이 오르고 있지만 추세적 상승으로 이어지긴 어렵다고 국토교통부는 전망했습니다.   올해와 내년 공급 물량이 충분하고,   금융당국도 가계대출을 관리 기조로 유지하고 있다는 점을 이유로 들었습니다.   신생아 특례대출 등  정책 금융이 집값을 자극했다는 지적에 대해선 출산 가구에 국한하고 집값 9억 원 이하라는 제한이 있다며   주택 가격이  상승하는 지역의 매매 가격과 비교하면 직접적인 연관은 없어 보인다고 설명했습니다.   최근 공사비 상승 등으로 주택 공급이 위축될 수 있다는 우려에는  철근 가격이 3~4년 전 수준으로 회복됐고,   관계기관 협의체를 가동해 지속적으로 해결 방안을 찾고 있다고 밝혔습니다.   KBS 뉴스, 손서영입니다.  ================= 촬영기자 조현관  영상편집 김기곤   \"|경제    |2024-07-04 17:14:18|2024-07-04 17:20:1720081258|\n",
      "+-----------+---------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+-------------------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_df.limit(1).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "835271d2-129e-4d2c-9618-f9fbb5c312c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, udf, date_format\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "udf_str_preprocess = udf(str_preprocess, StringType())\n",
    "processed_df = combined_df.\\\n",
    "                withColumn(\"articleTitle\", udf_str_preprocess(col(\"articleTitle\"))).\\\n",
    "                withColumn(\"articleContents\", udf_str_preprocess(col(\"articleContents\"))).\\\n",
    "                withColumn(\"regDate\", date_format(col(\"regDate\"), \"yyyy-MM-dd HH:mm:ss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f4fc5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------------------+----------------------------+--------+-------------------+--------------------+\n",
      "|institution|                 articleTitle|             articleContents|category|            regDate|             getDate|\n",
      "+-----------+-----------------------------+----------------------------+--------+-------------------+--------------------+\n",
      "|        KBS|\"(슈퍼5시)\"\"집값 추세 상승...|\" [앵커]   정부가 올해 하...|    경제|2024-07-04 17:14:18|2024-07-04 17:20:...|\n",
      "+-----------+-----------------------------+----------------------------+--------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_df.limit(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5af3ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- institution: string (nullable = true)\n",
      " |-- articleTitle: string (nullable = true)\n",
      " |-- articleContents: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- regDate: string (nullable = true)\n",
      " |-- getDate: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35957f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbc_url = \"jdbc:mariadb://:3306/your_database\"\n",
    "table_name = \"crawling\"\n",
    "connection_properties = {\n",
    "    \"user\": \"encore\",\n",
    "    \"password\": \"3playdata!!\",\n",
    "    \"port\": \"\"\n",
    "    \"driver\": \"org.mariadb.jdbc.Driver\"\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
